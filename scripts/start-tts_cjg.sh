#!/bin/bash
set -euo pipefail

PORT=${PORT:-9031}
HOST=${HOST:-0.0.0.0}
WORKERS=${WORKERS:-1}
GPU_ID=${GPU_ID:-0}
LOG_LEVEL=${LOG_LEVEL:-debug}

ROOT_DIR=$(cd "$(dirname "$0")/.." && pwd)
INFER_CODE="/root/MintaiDialect/models/tts_service/infer-code" # ä½ åŸå§‹ webui æ‰€åœ¨ç›®å½•ï¼ˆåŒ…å« indexttsï¼‰

export PYTHONPATH="${ROOT_DIR}:${INFER_CODE}"
export LOG_LEVEL
export MODEL_DIR="/root/MintaiDialect/models/tts_service/ckpt/cjg"

# ç¦ç”¨DS_BUILD_OPSå’ŒDS_SKIP_CUDA_CHECK,IndexTTS
# å¤§éƒ¨åˆ†åœºæ™¯å…¶å®ä¸éœ€è¦ DeepSpeedã€‚
# ä½ åªéœ€åœ¨è¿è¡Œç¯å¢ƒä¸­è®© DeepSpeed import å¤±è´¥å³å¯ã€‚
export DS_BUILD_OPS=0
export DS_SKIP_CUDA_CHECK=1


echo "ğŸ”Š å¯åŠ¨é™ˆå˜‰åºšTTSæ¨¡å‹æœåŠ¡ (ç«¯å£: $PORT, GPU: $GPU_ID, workers: $WORKERS, log: $LOG_LEVEL)"
cd "${ROOT_DIR}/models/tts_service"

# æ¿€æ´» conda envï¼ˆå¦‚éœ€è¦ï¼‰
source /root/miniconda3/bin/activate index-tts

CUDA_VISIBLE_DEVICES=$GPU_ID \
python -m uvicorn tts_service_cjg:app \
  --host "$HOST" \
  --port "$PORT" \
  --log-level "$LOG_LEVEL" \
  --workers "$WORKERS" \
  --reload \
  --reload-dir "$(pwd)"
